# Sistema de Vectorizaci√≥n y Consulta de Documentos PDF con LangChain y Chroma

Este proyecto implementa un sistema completo de **RAG (Retrieval-Augmented Generation)** que permite cargar documentos PDF, vectorizarlos y realizar consultas inteligentes usando LLMs.

## üèóÔ∏è Arquitectura del Sistema

```
üìÑ Documentos PDF ‚Üí üîç nomic-embed-text ‚Üí üóÑÔ∏è Chroma DB ‚Üí ü§ñ gpt-oss:20b ‚Üí üìù Respuesta
```

### Componentes:
- **Embeddings**: `nomic-embed-text:latest` (vectorizaci√≥n)
- **Base de datos**: Chroma en `localhost:8000` (almacenamiento)
- **LLM**: `gpt-oss:20b` (generaci√≥n de respuestas)
- **Servidor**: Ollama en `172.16.1.37:11434`

## üì¶ Versiones Instaladas

- **LangChain**: 0.3.27
- **LangChain Core**: 0.3.74
- **LangChain Community**: 0.0.38
- **LangChain Chroma**: 0.2.5
- **LangChain Ollama**: 0.1.0
- **ChromaDB**: 1.0.16
- **PyPDF**: 5.9.0

## ‚öôÔ∏è Configuraci√≥n del Sistema

### Configuraciones Importantes:

1. **Tama√±o de Chunks (CHUNK_SIZE)**: 1000 caracteres
   - Recomendado para documentos t√©cnicos/cient√≠ficos
   - Puedes ajustar seg√∫n el tipo de contenido

2. **Solapamiento de Chunks (CHUNK_OVERLAP)**: 200 caracteres
   - Mantiene contexto entre chunks adyacentes
   - Evita cortar frases importantes

3. **Puerto de Chroma**: 8000
   - Aseg√∫rate de que Chroma est√© ejecut√°ndose en este puerto

4. **Modelo de Embeddings**: nomic-embed-text:latest (Ollama)
   - Modelo especializado para embeddings
   - Requiere Ollama instalado con el modelo nomic-embed-text

5. **Modelo LLM**: gpt-oss:20b (Ollama)
   - Modelo para generaci√≥n de respuestas
   - Optimizado para velocidad y calidad

6. **Configuraci√≥n de Ollama**:
   - Host: 172.16.1.37
   - Puerto: 11434
   - Modelos: nomic-embed-text:latest, gpt-oss:20b

## üöÄ Instalaci√≥n y Configuraci√≥n

### 1. Crear ambiente conda:
```bash
conda create -n langchain_clean python=3.9
conda activate langchain_clean
```

### 2. Instalar dependencias:
```bash
pip install -r requirements_ultra_minimal.txt
```

### 3. Verificar que Chroma est√© ejecut√°ndose:
```bash
# Si usas Docker Compose
docker-compose up -d

# O iniciar Chroma manualmente en puerto 8000
```

### 4. Verificar que Ollama est√© disponible:
```bash
# Verificar que Ollama est√© instalado
ollama --version

# Verificar modelos disponibles
curl -s http://172.16.1.37:11434/api/tags | python -c "import sys, json; data=json.load(sys.stdin); print('Modelos disponibles:'); [print(f'- {model[\"name\"]}') for model in data['models']]"

# Si no tienes nomic-embed-text, instalarlo
curl -X POST http://172.16.1.37:11434/api/pull -d '{"name": "nomic-embed-text"}'
```

## üìã Uso del Sistema

### 1. Vectorizar Documentos PDF:
```bash
python ejemplo1.py
```

Este script:
- Carga todos los PDF de la carpeta `Documentos/`
- Los divide en chunks de 1000 caracteres
- Los vectoriza usando nomic-embed-text
- Los almacena en la base de datos Chroma

### 2. Consultar Documentos (B√∫squeda Simple):
```bash
python consultar_documentos.py
```

Este script permite:
- Realizar b√∫squedas sem√°nticas
- Ver estad√≠sticas de la base de datos
- Explorar contenido vectorizado

### 3. Consultar con LLM (Respuestas Inteligentes):
```bash
python consultar_con_llm.py
```

Este script combina:
- B√∫squeda sem√°ntica con embeddings
- Generaci√≥n de respuestas con LLM
- Respuestas contextualizadas y estructuradas

### 4. Monitorear Base de Datos:
```bash
python database_monitor.py
```

Este script permite:
- Verificar el estado de la base de datos
- Obtener estad√≠sticas detalladas
- Realizar consultas de diagn√≥stico
- Exportar reportes en JSON
- Modo interactivo para exploraci√≥n

### 5. Gestionar Base de Datos:
```bash
python limpiar_bd.py
```

Este script permite:
- Eliminar toda la colecci√≥n
- Eliminar documentos espec√≠ficos
- Eliminar directorio de datos
- Crear backups
- Modo interactivo para gesti√≥n

### 6. Analizar √çndices de la Base de Datos:
```bash
python ver_indices.py
```

Este script permite:
- Ver informaci√≥n b√°sica de √≠ndices
- Analizar estructura detallada de archivos
- Medir rendimiento de consultas
- Ver configuraci√≥n de √≠ndices
- Exportar reportes de √≠ndices
- Modo interactivo para an√°lisis

## üîß Configuraciones Recomendadas

### Para Diferentes Tipos de Contenido:

**Documentos T√©cnicos/Cient√≠ficos:**
- CHUNK_SIZE: 1000-1500 caracteres
- CHUNK_OVERLAP: 200-300 caracteres

**Documentos Narrativos:**
- CHUNK_SIZE: 800-1200 caracteres
- CHUNK_OVERLAP: 150-250 caracteres

**Documentos Legales/Contractuales:**
- CHUNK_SIZE: 1200-2000 caracteres
- CHUNK_OVERLAP: 300-500 caracteres

### Configuraci√≥n de la Base de Datos:

**Chroma Settings:**
```python
chroma_client = Chroma(
    collection_name="documentos_pdf",
    embedding_function=embeddings,
    persist_directory="chroma_data"
)
```

**Embeddings con nomic-embed-text:**
```python
embeddings = OllamaEmbeddings(
    model="nomic-embed-text:latest",
    base_url="http://172.16.1.37:11434"
)
```

**LLM con gpt-oss:20b:**
```python
llm = Ollama(
    model="gpt-oss:20b",
    base_url="http://172.16.1.37:11434"
)
```

## üìÅ Estructura del Proyecto

```
Ejemplo1/
‚îú‚îÄ‚îÄ ejemplo1.py                    # Script principal de vectorizaci√≥n
‚îú‚îÄ‚îÄ consultar_documentos.py        # Script de consultas simples
‚îú‚îÄ‚îÄ consultar_con_llm.py          # Script de consultas con LLM
‚îú‚îÄ‚îÄ database_monitor.py           # Monitor de base de datos
‚îú‚îÄ‚îÄ limpiar_bd.py                 # Script de limpieza y gesti√≥n
‚îú‚îÄ‚îÄ ver_indices.py                # Analizador de √≠ndices
‚îú‚îÄ‚îÄ test_system.py                # Script de pruebas del sistema
‚îú‚îÄ‚îÄ config.py                     # Configuraci√≥n centralizada
‚îú‚îÄ‚îÄ requirements_ultra_minimal.txt # Dependencias exactas
‚îú‚îÄ‚îÄ docker-compose.yml            # Configuraci√≥n de Chroma
‚îú‚îÄ‚îÄ README.md                     # Documentaci√≥n
‚îú‚îÄ‚îÄ .gitignore                    # Archivos a ignorar
‚îú‚îÄ‚îÄ Documentos/                   # Carpeta con PDFs
‚îÇ   ‚îú‚îÄ‚îÄ 2502.12524v1.pdf
‚îÇ   ‚îî‚îÄ‚îÄ 2410.17725v1.pdf
‚îî‚îÄ‚îÄ chroma_data/                  # Datos persistentes de Chroma
```

## üîç Soluci√≥n de Problemas

### Error de Conexi√≥n con Chroma:
- Verificar que Chroma est√© ejecut√°ndose en puerto 8000
- Revisar logs de Docker: `docker-compose logs`

### Error de Embeddings:
- Verificar que Ollama est√© instalado
- Descargar modelo: `curl -X POST http://172.16.1.37:11434/api/pull -d '{"name": "nomic-embed-text"}'`
- Verificar que el modelo est√© disponible

### Error al Cargar PDFs:
- Verificar que los archivos PDF no est√©n corruptos
- Asegurar permisos de lectura en la carpeta Documentos

### Error de LLM:
- Verificar que gpt-oss:20b est√© disponible en el servidor
- Comprobar conectividad con 172.16.1.37:11434

## üìä Monitoreo y Mantenimiento

### Monitor de Base de Datos:
```bash
# Verificaci√≥n completa autom√°tica
python database_monitor.py

# Modo interactivo para exploraci√≥n
python database_monitor.py
# Luego usar comandos: stats, detailed, search, health, export, quit
```

### Funcionalidades del Monitor:
- **Estad√≠sticas b√°sicas**: Conteo de documentos, metadatos
- **Estad√≠sticas detalladas**: An√°lisis de longitud, fuentes, p√°ginas
- **Pruebas de b√∫squeda**: Verificaci√≥n de consultas sem√°nticas
- **Verificaci√≥n de salud**: Estado general de la base de datos
- **Exportaci√≥n**: Reportes en formato JSON
- **Modo interactivo**: Exploraci√≥n interactiva de la BD

### Verificar Estado de la Base de Datos:
```python
# En consultar_documentos.py
obtener_estadisticas(chroma_client)
```

### Limpiar Base de Datos:
```python
# Eliminar colecci√≥n si es necesario
chroma_client.delete_collection()
```

### Backup de Datos:
- Los datos se guardan en `chroma_data/`
- Hacer backup regular de esta carpeta

## üóëÔ∏è Gesti√≥n y Limpieza de la Base de Datos

### üîÑ Reemplazar Documentos Completamente

Si quieres cambiar todos los documentos y empezar desde cero:

#### Opci√≥n 1: Eliminar Colecci√≥n (Recomendado)
```python
# En un script Python o en el int√©rprete
from langchain_chroma import Chroma
from langchain_ollama import OllamaEmbeddings
from config import get_ollama_config, get_chroma_config, get_models_config

# Inicializar cliente
config = get_chroma_config()
ollama_config = get_ollama_config()
models_config = get_models_config()

embeddings = OllamaEmbeddings(
    model=models_config["embedding_model"],
    base_url=ollama_config["base_url"]
)

chroma_client = Chroma(
    collection_name=config["collection_name"],
    embedding_function=embeddings,
    persist_directory=config["persist_directory"]
)

# Eliminar toda la colecci√≥n
chroma_client.delete_collection()
print("‚úÖ Colecci√≥n eliminada completamente")

# Ahora puedes ejecutar ejemplo1.py para vectorizar nuevos documentos
```

#### Opci√≥n 2: Eliminar Directorio de Datos
```bash
# Detener Chroma si est√° ejecut√°ndose
docker-compose down

# Eliminar directorio de datos
rm -rf chroma_data/

# Reiniciar Chroma
docker-compose up -d

# Ejecutar vectorizaci√≥n de nuevos documentos
python ejemplo1.py
```

#### Opci√≥n 3: Script de Limpieza Autom√°tica
```python
# Crear archivo: limpiar_bd.py
import shutil
import os
from config import get_chroma_config

def limpiar_base_datos():
    """Limpia completamente la base de datos"""
    config = get_chroma_config()
    
    print("üóëÔ∏è Limpiando base de datos...")
    
    # Opci√≥n 1: Eliminar directorio completo
    if os.path.exists(config["persist_directory"]):
        shutil.rmtree(config["persist_directory"])
        print(f"‚úÖ Directorio {config['persist_directory']} eliminado")
    
    # Opci√≥n 2: Eliminar solo archivos de datos
    # for file in os.listdir(config["persist_directory"]):
    #     if file.endswith('.parquet') or file.endswith('.sqlite3'):
    #         os.remove(os.path.join(config["persist_directory"], file))
    #         print(f"‚úÖ Archivo {file} eliminado")
    
    print("üéâ Base de datos limpiada. Ejecuta 'python ejemplo1.py' para vectorizar nuevos documentos")

if __name__ == "__main__":
    limpiar_base_datos()
```

### üìù Eliminar Documentos Espec√≠ficos

Para eliminar solo ciertos documentos:

```python
# Eliminar documentos por fuente
from langchain_chroma import Chroma
from langchain_ollama import OllamaEmbeddings
from config import get_ollama_config, get_chroma_config, get_models_config

# Inicializar cliente
config = get_chroma_config()
ollama_config = get_ollama_config()
models_config = get_models_config()

embeddings = OllamaEmbeddings(
    model=models_config["embedding_model"],
    base_url=ollama_config["base_url"]
)

chroma_client = Chroma(
    collection_name=config["collection_name"],
    embedding_function=embeddings,
    persist_directory=config["persist_directory"]
)

# Obtener todos los documentos
results = chroma_client.get()

# Encontrar IDs de documentos espec√≠ficos
documentos_a_eliminar = []
for i, metadata in enumerate(results['metadatas']):
    if metadata and 'source' in metadata:
        # Ejemplo: eliminar documentos de un PDF espec√≠fico
        if 'documento_especifico.pdf' in metadata['source']:
            documentos_a_eliminar.append(results['ids'][i])

# Eliminar documentos espec√≠ficos
if documentos_a_eliminar:
    chroma_client.delete(ids=documentos_a_eliminar)
    print(f"‚úÖ {len(documentos_a_eliminar)} documentos eliminados")
else:
    print("‚ÑπÔ∏è No se encontraron documentos para eliminar")
```

### üîç Verificar Estado Antes de Limpiar

```bash
# Verificar contenido actual
python database_monitor.py

# Ver estad√≠sticas b√°sicas
python -c "
from langchain_chroma import Chroma
from langchain_ollama import OllamaEmbeddings
from config import get_ollama_config, get_chroma_config, get_models_config

config = get_chroma_config()
ollama_config = get_ollama_config()
models_config = get_models_config()

embeddings = OllamaEmbeddings(
    model=models_config['embedding_model'],
    base_url=ollama_config['base_url']
)

chroma_client = Chroma(
    collection_name=config['collection_name'],
    embedding_function=embeddings,
    persist_directory=config['persist_directory']
)

count = chroma_client._collection.count()
print(f'üìä Documentos actuales: {count}')

if count > 0:
    results = chroma_client.get()
    sources = set()
    for metadata in results['metadatas']:
        if metadata and 'source' in metadata:
            sources.add(metadata['source'])
    
    print('üìÅ Fuentes actuales:')
    for source in sources:
        print(f'   - {source}')
"
```

### üìã Flujo de Trabajo para Cambiar Documentos

1. **Verificar estado actual:**
   ```bash
   python database_monitor.py
   ```

2. **Limpiar base de datos:**
   ```bash
   # Opci√≥n A: Usar script de limpieza
   python limpiar_bd.py
   
   # Opci√≥n B: Eliminar colecci√≥n manualmente
   chroma_client.delete_collection()
   
   # Opci√≥n C: Eliminar directorio
   rm -rf chroma_data/
   ```

3. **Colocar nuevos documentos:**
   ```bash
   # Reemplazar archivos en Documentos/
   cp nuevos_documentos.pdf Documentos/
   ```

4. **Vectorizar nuevos documentos:**
   ```bash
   python ejemplo1.py
   ```

5. **Verificar resultado:**
   ```bash
   python database_monitor.py
   ```

### ‚ö†Ô∏è Consideraciones Importantes

- **Backup**: Antes de limpiar, considera hacer backup de `chroma_data/`
- **Tiempo**: La vectorizaci√≥n puede tomar tiempo dependiendo del tama√±o de los documentos
- **Espacio**: Los vectores ocupan espacio significativo en disco
- **Persistencia**: Los datos se mantienen entre reinicios del sistema
- **Concurrencia**: No ejecutar m√∫ltiples procesos de vectorizaci√≥n simult√°neamente

### üõ†Ô∏è Scripts de Utilidad

#### Backup de Base de Datos:
```bash
# Crear backup con timestamp
tar -czf backup_chroma_$(date +%Y%m%d_%H%M%S).tar.gz chroma_data/
```

#### Restaurar Backup:
```bash
# Restaurar desde backup
tar -xzf backup_chroma_20241224_143022.tar.gz
```

#### Verificar Tama√±o de Datos:
```bash
# Ver tama√±o del directorio de datos
du -sh chroma_data/
```

## üîç An√°lisis de √çndices de la Base de Datos

### ¬øQu√© Informaci√≥n Proporcionan los √çndices?

Los √≠ndices en Chroma DB contienen informaci√≥n muy valiosa sobre:

#### üìä **Informaci√≥n Estructural:**
- **Archivos de √≠ndices**: `data_level0.bin`, `chroma.sqlite3`, `header.bin`, etc.
- **Tama√±o de archivos**: Distribuci√≥n del espacio en disco
- **Tipo de √≠ndice**: HNSW (Hierarchical Navigable Small World)
- **Dimensi√≥n de vectores**: 768 dimensiones para nomic-embed-text

#### ‚ö° **M√©tricas de Rendimiento:**
- **Tiempo de consulta**: Milisegundos por b√∫squeda
- **Distribuci√≥n de documentos**: Chunks por PDF y por p√°gina
- **Eficiencia de b√∫squeda**: Velocidad de recuperaci√≥n de resultados

#### üèóÔ∏è **Configuraci√≥n del Sistema:**
- **Modelo de embeddings**: nomic-embed-text:latest
- **Dimensi√≥n de vectores**: 768
- **Tama√±o de chunks**: 1000 caracteres
- **Solapamiento**: 200 caracteres

### üìà **Informaci√≥n Valiosa Revelada:**

#### **Estructura de Archivos:**
```
üìÅ chroma_data/
‚îú‚îÄ‚îÄ chroma.sqlite3: 2.07 MB (metadatos)
‚îú‚îÄ‚îÄ data_level0.bin: 30.63 MB (vectores)
‚îú‚îÄ‚îÄ header.bin: 0.00 MB (cabeceras)
‚îú‚îÄ‚îÄ length.bin: 0.04 MB (longitudes)
‚îî‚îÄ‚îÄ link_lists.bin: 0.00 MB (enlaces HNSW)
```

#### **Rendimiento de Consultas:**
- **'YOLO'**: 1054.36ms (primera consulta, m√°s lenta)
- **'detection'**: 64.91ms (consultas subsecuentes, m√°s r√°pidas)
- **'model'**: 86.24ms
- **'architecture'**: 66.23ms

#### **Distribuci√≥n de Datos:**
- **Total**: 114 chunks
- **YOLOv11**: 40 chunks (35.1%)
- **YOLOv12**: 74 chunks (64.9%)
- **P√°ginas**: Distribuci√≥n equilibrada (4.4% - 11.4% por p√°gina)

### üéØ **Valor de la Informaci√≥n de √çndices:**

1. **Optimizaci√≥n de Rendimiento**: Identificar consultas lentas
2. **Gesti√≥n de Espacio**: Monitorear uso de disco
3. **Balanceo de Datos**: Verificar distribuci√≥n de documentos
4. **Diagn√≥stico de Problemas**: Detectar √≠ndices corruptos
5. **Planificaci√≥n de Escalabilidad**: Predecir necesidades de recursos

### üîß **Uso del Analizador de √çndices:**

```bash
# An√°lisis completo autom√°tico
python ver_indices.py

# Modo interactivo
python ver_indices.py
# Comandos: basic, structure, performance, config, export, quit
```

## ‚ö° Rendimiento y Optimizaci√≥n

### Para Grandes Vol√∫menes:
- Aumentar CHUNK_SIZE para reducir n√∫mero de chunks
- Usar procesamiento por lotes
- Considerar m√∫ltiples colecciones por tipo de documento

### Para Consultas R√°pidas:
- Indexar metadatos importantes
- Usar filtros en las consultas
- Optimizar queries con par√°metros espec√≠ficos

### Cambio de Modelos:
Para cambiar el LLM, modifica esta l√≠nea en `consultar_con_llm.py`:
```python
LLM_MODEL = "gpt-oss:120b"  # Cambia por el modelo deseado
```

Modelos disponibles en el servidor:
- gpt-oss:20b (recomendado - velocidad/calidad)
- gpt-oss:120b (m√°s potente - m√°s lento)
- gemma3:12b
- deepseek-r1:latest
- llama3.1:8b

## ‚úÖ Verificaci√≥n de la Instalaci√≥n

### Verificaci√≥n Completa del Sistema:
```bash
# Ejecutar todas las pruebas autom√°ticamente
python test_system.py
```

### Verificaci√≥n de la Base de Datos:
```bash
# Verificar estado y contenido de la base de datos
python database_monitor.py
```

### Verificaci√≥n Manual de Librer√≠as:
```bash
# Verificar que todas las librer√≠as est√©n instaladas correctamente
python -c "
import langchain
import langchain_core
import langchain_community
import langchain_chroma
import langchain_ollama
import chromadb
import pypdf
print('‚úì Todas las librer√≠as instaladas correctamente')
print(f'LangChain: {langchain.__version__}')
print(f'LangChain Core: {langchain_core.__version__}')
print(f'LangChain Community: {langchain_community.__version__}')
print(f'LangChain Chroma: Instalado')
print(f'LangChain Ollama: {langchain_ollama.__version__}')
print(f'ChromaDB: {chromadb.__version__}')
"

# Verificar que los modelos est√©n disponibles
curl -s http://172.16.1.37:11434/api/tags | python -c "import sys, json; data=json.load(sys.stdin); print('Modelos disponibles:'); [print(f'- {model[\"name\"]}') for model in data['models']]"
```

## üéØ Casos de Uso

### 1. Investigaci√≥n Acad√©mica:
- Cargar papers cient√≠ficos
- Hacer consultas espec√≠ficas sobre metodolog√≠as
- Obtener respuestas contextualizadas

### 2. Documentaci√≥n T√©cnica:
- Indexar manuales t√©cnicos
- Buscar soluciones espec√≠ficas
- Generar res√∫menes autom√°ticos

### 3. An√°lisis de Documentos:
- Procesar reportes empresariales
- Extraer informaci√≥n clave
- Generar insights autom√°ticos

## üîÑ Flujo de Trabajo T√≠pico

1. **Preparaci√≥n**: Colocar PDFs en carpeta `Documentos/`
2. **Vectorizaci√≥n**: Ejecutar `python ejemplo1.py`
3. **Verificaci√≥n del Sistema**: Ejecutar `python test_system.py`
4. **Verificaci√≥n de la BD**: Ejecutar `python database_monitor.py`
5. **Consulta**: Ejecutar `python consultar_con_llm.py`
6. **Mantenimiento**: Backup regular de `chroma_data/`

### üîÑ Flujo para Cambiar Documentos:

1. **Verificar estado**: `python database_monitor.py`
2. **Limpiar BD**: `python limpiar_bd.py`
3. **Reemplazar PDFs**: Copiar nuevos archivos a `Documentos/`
4. **Vectorizar**: `python ejemplo1.py`
5. **Verificar**: `python database_monitor.py`

## üìà M√©tricas del Sistema

- **Documentos procesados**: 2 PDFs
- **Chunks generados**: 114
- **Tiempo de vectorizaci√≥n**: ~30 segundos
- **Tiempo de consulta**: ~2-5 segundos
- **Precisi√≥n de b√∫squeda**: Alta (embeddings sem√°nticos)
- **Calidad de respuestas**: Excelente (LLM contextual)
